<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>audiocraft.models.watermark API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>audiocraft.models.watermark</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="audiocraft.models.watermark.AudioSeal"><code class="flex name class">
<span>class <span class="ident">AudioSeal</span></span>
<span>(</span><span>generator: torch.nn.modules.module.Module,<br>detector: torch.nn.modules.module.Module,<br>nbits: int = 0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AudioSeal(WMModel):
    &#34;&#34;&#34;Wrap Audioseal (https://github.com/facebookresearch/audioseal) for the
    training and evaluation. The generator and detector are jointly trained
    &#34;&#34;&#34;

    def __init__(
        self,
        generator: nn.Module,
        detector: nn.Module,
        nbits: int = 0,
    ):
        super().__init__()
        self.generator = generator  # type: ignore
        self.detector = detector  # type: ignore

        # Allow to re-train an n-bit model with new 0-bit message
        self.nbits = nbits if nbits else self.generator.msg_processor.nbits

    def get_watermark(
        self,
        x: torch.Tensor,
        message: tp.Optional[torch.Tensor] = None,
        sample_rate: int = 16_000,
    ) -&gt; torch.Tensor:
        return self.generator.get_watermark(x, message=message, sample_rate=sample_rate)

    def detect_watermark(self, x: torch.Tensor) -&gt; torch.Tensor:
        &#34;&#34;&#34;
        Detect the watermarks from the audio signal.  The first two units of the output
        are used for detection, the rest is used to decode the message. If the audio is
        not watermarked, the message will be random.

        Args:
            x: Audio signal, size batch x frames
        Returns
            torch.Tensor: Detection + decoding results of shape (B, 2+nbits, T).
        &#34;&#34;&#34;

        # Getting the direct decoded message from the detector
        result = self.detector.detector(x)  # b x 2+nbits
        # hardcode softmax on 2 first units used for detection
        result[:, :2, :] = torch.softmax(result[:, :2, :], dim=1)
        return result

    def forward(  # generator
        self,
        x: torch.Tensor,
        message: tp.Optional[torch.Tensor] = None,
        sample_rate: int = 16_000,
        alpha: float = 1.0,
    ) -&gt; torch.Tensor:
        &#34;&#34;&#34;Apply the watermarking to the audio signal x with a tune-down ratio (default 1.0)&#34;&#34;&#34;
        wm = self.get_watermark(x, message)
        return x + alpha * wm

    @staticmethod
    def get_pretrained(name=&#34;base&#34;, device=None) -&gt; WMModel:
        if device is None:
            if torch.cuda.device_count():
                device = &#34;cuda&#34;
            else:
                device = &#34;cpu&#34;
        return load_audioseal_models(&#34;facebook/audioseal&#34;, filename=name, device=device)</code></pre>
</details>
<div class="desc"><p>Wrap Audioseal (<a href="https://github.com/facebookresearch/audioseal">https://github.com/facebookresearch/audioseal</a>) for the
training and evaluation. The generator and detector are jointly trained</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="audiocraft.models.watermark.WMModel" href="#audiocraft.models.watermark.WMModel">WMModel</a></li>
<li>abc.ABC</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="audiocraft.models.watermark.AudioSeal.get_pretrained"><code class="name flex">
<span>def <span class="ident">get_pretrained</span></span>(<span>name='base', device=None) ‑> <a title="audiocraft.models.watermark.WMModel" href="#audiocraft.models.watermark.WMModel">WMModel</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def get_pretrained(name=&#34;base&#34;, device=None) -&gt; WMModel:
    if device is None:
        if torch.cuda.device_count():
            device = &#34;cuda&#34;
        else:
            device = &#34;cpu&#34;
    return load_audioseal_models(&#34;facebook/audioseal&#34;, filename=name, device=device)</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="audiocraft.models.watermark.AudioSeal.detect_watermark"><code class="name flex">
<span>def <span class="ident">detect_watermark</span></span>(<span>self, x: torch.Tensor) ‑> torch.Tensor</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def detect_watermark(self, x: torch.Tensor) -&gt; torch.Tensor:
    &#34;&#34;&#34;
    Detect the watermarks from the audio signal.  The first two units of the output
    are used for detection, the rest is used to decode the message. If the audio is
    not watermarked, the message will be random.

    Args:
        x: Audio signal, size batch x frames
    Returns
        torch.Tensor: Detection + decoding results of shape (B, 2+nbits, T).
    &#34;&#34;&#34;

    # Getting the direct decoded message from the detector
    result = self.detector.detector(x)  # b x 2+nbits
    # hardcode softmax on 2 first units used for detection
    result[:, :2, :] = torch.softmax(result[:, :2, :], dim=1)
    return result</code></pre>
</details>
<div class="desc"><p>Detect the watermarks from the audio signal.
The first two units of the output
are used for detection, the rest is used to decode the message. If the audio is
not watermarked, the message will be random.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong></dt>
<dd>Audio signal, size batch x frames</dd>
</dl>
<p>Returns
torch.Tensor: Detection + decoding results of shape (B, 2+nbits, T).</p></div>
</dd>
<dt id="audiocraft.models.watermark.AudioSeal.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self,<br>x: torch.Tensor,<br>message: torch.Tensor | None = None,<br>sample_rate: int = 16000,<br>alpha: float = 1.0) ‑> torch.Tensor</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(  # generator
    self,
    x: torch.Tensor,
    message: tp.Optional[torch.Tensor] = None,
    sample_rate: int = 16_000,
    alpha: float = 1.0,
) -&gt; torch.Tensor:
    &#34;&#34;&#34;Apply the watermarking to the audio signal x with a tune-down ratio (default 1.0)&#34;&#34;&#34;
    wm = self.get_watermark(x, message)
    return x + alpha * wm</code></pre>
</details>
<div class="desc"><p>Apply the watermarking to the audio signal x with a tune-down ratio (default 1.0)</p></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="audiocraft.models.watermark.WMModel" href="#audiocraft.models.watermark.WMModel">WMModel</a></b></code>:
<ul class="hlist">
<li><code><a title="audiocraft.models.watermark.WMModel.get_watermark" href="#audiocraft.models.watermark.WMModel.get_watermark">get_watermark</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="audiocraft.models.watermark.WMModel"><code class="flex name class">
<span>class <span class="ident">WMModel</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class WMModel(ABC, nn.Module):
    &#34;&#34;&#34;
    A wrapper interface to different watermarking models for
    training or evaluation purporses
    &#34;&#34;&#34;

    @abstractmethod
    def get_watermark(
        self,
        x: torch.Tensor,
        message: tp.Optional[torch.Tensor] = None,
        sample_rate: int = 16_000,
    ) -&gt; torch.Tensor:
        &#34;&#34;&#34;Get the watermark from an audio tensor and a message.
        If the input message is None, a random message of
        n bits {0,1} will be generated
        &#34;&#34;&#34;

    @abstractmethod
    def detect_watermark(self, x: torch.Tensor) -&gt; torch.Tensor:
        &#34;&#34;&#34;Detect the watermarks from the audio signal

        Args:
            x: Audio signal, size batch x frames

        Returns:
            tensor of size (B, 2+n, frames) where:
            Detection results of shape (B, 2, frames)
            Message decoding results of shape (B, n, frames)
        &#34;&#34;&#34;</code></pre>
</details>
<div class="desc"><p>A wrapper interface to different watermarking models for
training or evaluation purporses</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="audiocraft.models.watermark.AudioSeal" href="#audiocraft.models.watermark.AudioSeal">AudioSeal</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="audiocraft.models.watermark.WMModel.detect_watermark"><code class="name flex">
<span>def <span class="ident">detect_watermark</span></span>(<span>self, x: torch.Tensor) ‑> torch.Tensor</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def detect_watermark(self, x: torch.Tensor) -&gt; torch.Tensor:
    &#34;&#34;&#34;Detect the watermarks from the audio signal

    Args:
        x: Audio signal, size batch x frames

    Returns:
        tensor of size (B, 2+n, frames) where:
        Detection results of shape (B, 2, frames)
        Message decoding results of shape (B, n, frames)
    &#34;&#34;&#34;</code></pre>
</details>
<div class="desc"><p>Detect the watermarks from the audio signal</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong></dt>
<dd>Audio signal, size batch x frames</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>tensor of size (B, 2+n, frames) where:
Detection results of shape (B, 2, frames)
Message decoding results of shape (B, n, frames)</p></div>
</dd>
<dt id="audiocraft.models.watermark.WMModel.get_watermark"><code class="name flex">
<span>def <span class="ident">get_watermark</span></span>(<span>self,<br>x: torch.Tensor,<br>message: torch.Tensor | None = None,<br>sample_rate: int = 16000) ‑> torch.Tensor</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def get_watermark(
    self,
    x: torch.Tensor,
    message: tp.Optional[torch.Tensor] = None,
    sample_rate: int = 16_000,
) -&gt; torch.Tensor:
    &#34;&#34;&#34;Get the watermark from an audio tensor and a message.
    If the input message is None, a random message of
    n bits {0,1} will be generated
    &#34;&#34;&#34;</code></pre>
</details>
<div class="desc"><p>Get the watermark from an audio tensor and a message.
If the input message is None, a random message of
n bits {0,1} will be generated</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="audiocraft.models" href="index.html">audiocraft.models</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="audiocraft.models.watermark.AudioSeal" href="#audiocraft.models.watermark.AudioSeal">AudioSeal</a></code></h4>
<ul class="">
<li><code><a title="audiocraft.models.watermark.AudioSeal.detect_watermark" href="#audiocraft.models.watermark.AudioSeal.detect_watermark">detect_watermark</a></code></li>
<li><code><a title="audiocraft.models.watermark.AudioSeal.forward" href="#audiocraft.models.watermark.AudioSeal.forward">forward</a></code></li>
<li><code><a title="audiocraft.models.watermark.AudioSeal.get_pretrained" href="#audiocraft.models.watermark.AudioSeal.get_pretrained">get_pretrained</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="audiocraft.models.watermark.WMModel" href="#audiocraft.models.watermark.WMModel">WMModel</a></code></h4>
<ul class="">
<li><code><a title="audiocraft.models.watermark.WMModel.detect_watermark" href="#audiocraft.models.watermark.WMModel.detect_watermark">detect_watermark</a></code></li>
<li><code><a title="audiocraft.models.watermark.WMModel.get_watermark" href="#audiocraft.models.watermark.WMModel.get_watermark">get_watermark</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
